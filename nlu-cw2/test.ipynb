{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('europarl_raw/train.en', 'r') as file:\n",
    "    # Read the file line by line\n",
    "    for line in file:\n",
    "        # Process each line as needed\n",
    "        lines.append(line.strip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it fell . 3\n",
      "what an explanation ! 4\n",
      "i voted against . 4\n",
      "nothing has happened . 4\n",
      "i agree . 3\n",
      "every day counts . 4\n",
      "i am voting in favour . is there anyone who will be against ? 14\n",
      "the process of introducing these products into the market is stagnating . 12\n",
      "arms exports are killing people all over the world . 10\n",
      "there are four points i would make here . 9\n"
     ]
    }
   ],
   "source": [
    "indexes= [6227,  447, 7952, 4216, 4228, 9892, 7145, 9924, 1954, 2850]\n",
    "\n",
    "for index in indexes:\n",
    "    print(lines[index], len(lines[index].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/shobhitmaheshwari/miniconda3/envs/nlu2/lib/python3.10/site-packages (from seaborn) (1.26.4)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Downloading pandas-2.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Downloading matplotlib-3.8.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading fonttools-4.49.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/shobhitmaheshwari/miniconda3/envs/nlu2/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Using cached pillow-10.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/shobhitmaheshwari/miniconda3/envs/nlu2/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shobhitmaheshwari/miniconda3/envs/nlu2/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.3-cp310-cp310-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.1-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.2.0-cp310-cp310-macosx_11_0_arm64.whl (242 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl (66 kB)\n",
      "Using cached pillow-10.2.0-cp310-cp310-macosx_11_0_arm64.whl (3.3 MB)\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3 pandas-2.2.1 pillow-10.2.0 pyparsing-3.1.2 pytz-2024.1 seaborn-0.13.2 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a source dictionary (de) with 5047 words\n",
      "Loaded a target dictionary (en) with 4420 words\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTMModel:\n\tUnexpected key(s) in state_dict: \"decoder.lexical_projection_hidden.weight\", \"decoder.lexical_projection_output.weight\", \"decoder.lexical_projection_output.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Build model and optimization criterion\u001b[39;00m\n\u001b[1;32m     46\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mbuild_model(args, src_dict, tgt_dict)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded a model from checkpoint \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(args\u001b[38;5;241m.\u001b[39mcheckpoint_path))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlu2/lib/python3.10/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTMModel:\n\tUnexpected key(s) in state_dict: \"decoder.lexical_projection_hidden.weight\", \"decoder.lexical_projection_output.weight\", \"decoder.lexical_projection_output.bias\". "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.serialization import default_restore_location\n",
    "\n",
    "from seq2seq import models, utils\n",
    "from seq2seq.data.dictionary import Dictionary\n",
    "from seq2seq.data.dataset import Seq2SeqDataset, BatchSampler\n",
    "\n",
    "import argparse\n",
    "\n",
    "dict_data = {'data': 'europarl_prepared', 'source_lang': 'de', 'target_lang': 'en', 'max_tokens': None, 'batch_size': 10, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 100, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 10, 'log_file': None, 'save_dir': 'checkpoints', 'restore_file': 'None', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'decoder_use_lexical_model': 'True', 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'device_id': 0}\n",
    "args = argparse.Namespace(**dict_data)\n",
    "\n",
    "\n",
    "mpl.rc('font', family='VL Gothic')\n",
    "data='europarl_prepared'\n",
    "torch.manual_seed(42)\n",
    "state_dict = torch.load('checkpoints/checkpoint_best.pt')\n",
    "source_lang, target_lang = 'de', 'en'\n",
    "src_dict = Dictionary.load(os.path.join(data, 'dict.{:s}'.format(source_lang)))\n",
    "print('Loaded a source dictionary ({:s}) with {:d} words'.format(source_lang, len(src_dict)))\n",
    "tgt_dict = Dictionary.load(os.path.join(data, 'dict.{:s}'.format(target_lang)))\n",
    "print('Loaded a target dictionary ({:s}) with {:d} words'.format(target_lang, len(tgt_dict)))\n",
    "\n",
    "    # Load dataset\n",
    "test_dataset = Seq2SeqDataset(\n",
    "    src_file=os.path.join(data, 'test.{:s}'.format(source_lang)),\n",
    "    tgt_file=os.path.join(data, 'test.{:s}'.format(target_lang)),\n",
    "    src_dict=src_dict, tgt_dict=tgt_dict)\n",
    "\n",
    "vis_loader = torch.utils.data.DataLoader(test_dataset, num_workers=1, collate_fn=test_dataset.collater,\n",
    "                                             batch_sampler=BatchSampler(test_dataset, None, 1, 1, 0, shuffle=False,\n",
    "                                                                        seed=42))\n",
    "args=Args()\n",
    "    # Build model and optimization criterion\n",
    "model = models.build_model(args, src_dict, tgt_dict)\n",
    "model.load_state_dict(state_dict['model'])\n",
    "print('Loaded a model from checkpoint {:s}'.format(args.checkpoint_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: Sequence to Sequence Model [-h] [--cuda CUDA] [--seed SEED]\n",
      "                                  [--data DATA]\n",
      "                                  [--checkpoint-path CHECKPOINT_PATH]\n",
      "                                  [--batch-size BATCH_SIZE] [--output OUTPUT]\n",
      "                                  [--max-len MAX_LEN]\n",
      "Sequence to Sequence Model: error: unrecognized arguments: --f=/Users/shobhitmaheshwari/Library/Jupyter/runtime/kernel-v2-25382CAOf2XInVME.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shobhitmaheshwari/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
